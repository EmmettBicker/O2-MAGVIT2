model:
    quantize_model:
        quantizer_type: lfq
        skip_quantize: false
        codebook_size: 262144 # 2**18
        token_size: 18
        use_l2_norm: false

    encoder:
        filters: 128 
        num_res_blocks: 4
        channel_multipliers: [1, 1, 2, 2, 4]
    decoder:
        filters: 128
        num_res_blocks: 4
        channel_multipliers: [1, 1, 2, 2, 4]

    discriminator: 
        filters: 128
        channel_multipliers: [2,2,4,4,4]

data: 
    spatial_size: 256

seed: 42
modal: image
architecture: magvit2
